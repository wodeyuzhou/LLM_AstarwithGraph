{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc8945f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566efd48f3a54563bde803da69c04d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "tokenizer.model_max_length = model.config.max_position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4eb6cc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜>Give me a short introduction to large language model.<｜Assistant｜><think>\n",
      "\n",
      "<｜begin▁of▁sentence｜>\n",
      "<｜User｜>\n",
      "Give me a short introduction to large language model.\n",
      "<｜Assistant｜><think>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=True\n",
    ")\n",
    "\n",
    "print(text)\n",
    "text = \"\"\"<｜begin▁of▁sentence｜>\n",
    "<｜User｜>\n",
    "Give me a short introduction to large language model.\n",
    "<｜Assistant｜><think>\"\"\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c17ec08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=32768\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(128014)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7a30fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128014"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"</think>\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3cf03d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids[::-1].index(128014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9795fa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(128014)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea4a521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay, so I need to write a short introduction to large language models. Hmm, I remember that large language models are related to AI, but I\\'m not exactly sure about all the details. Let me try to break it down.\\n\\nFirst, I think they\\'re a type of AI, probably part of machine learning. I\\'ve heard terms like deep learning and neural networks before, so maybe they use those. They must be designed to understand and generate human language, like how we use them to chat or write text.\\n\\nWait, but what makes them \"large\"? Is it just the size of the model? I think it refers to the size in terms of data and parameters. So they\\'re trained on a lot of data, which makes them more powerful but also more complex.\\n\\nI should mention their applications. Maybe things like text generation, answering questions, translating languages, or helping with creative tasks. They can write essays, poems, or even code. But I\\'ve also heard they can be used for tasks that require understanding context, like summarizing information or providing explanations.\\n\\nAre there different types? I think there are transformer models, like GPT-3 or BERT, which are quite popular. They use a transformer architecture which allows them to process sequences of text in a way that\\'s more efficient than older models.\\n\\nLimitations might include that they sometimes generate incorrect or biased information because they\\'re trained on existing data, which can have biases. Also, they can be expensive to run and require a lot of computational power.\\n\\nI should structure this introduction by defining what they are, their purpose, how they work, their capabilities, and their limitations. Maybe also mention how they\\'re used in real-world applications.\\n\\nWait, I should check if I\\'m missing anything. Oh, maybe their training process. They\\'re usually trained on vast amounts of text from the internet, which allows them to learn patterns and generate text based on that.\\n\\nSo, putting it all together, a short intro would introduce them as AI models trained on vast text data, using neural networks, capable of generating text, understanding context, used in various applications, but with limitations like computational needs and potential biases.\\n</think>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(thinking_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fdf49d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large language models (LLMs) are advanced AI systems designed to understand and generate human language. Trained on vast amounts of text data using deep learning techniques, they can perform tasks like text generation, question answering, and language translation. These models, such as GPT-3 and BERT, use neural networks to process and analyze text, enabling them to produce coherent and contextually relevant outputs. While they excel in creative and analytical tasks, they have limitations, including computational costs and potential biases from their training data. Overall, LLMs are versatile tools with wide-ranging applications across industries, though their effectiveness can vary depending on their specific design and training.\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c9d9c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜User｜>\n",
      "Give me a short introduction to large language model.\n",
      "<｜Assistant｜><think>\n",
      "Okay, so I need to write a short introduction to large language models. Hmm, where do I start? I know that large language models, or LLMs, are a type of AI that can understand and generate human language. But I'm not exactly sure about all the details. Let me think about what I know.\n",
      "\n",
      "First, I remember that LLMs are trained on a lot of data. They probably use big datasets, maybe from books, websites, and other sources. This training helps them recognize patterns in the language, right? So they can understand how words are used and how they relate to each other.\n",
      "\n",
      "Wait, how do they work exactly? I think they use something called deep learning. Maybe neural networks? Yeah, I've heard of that. So, they have layers of neurons that process the data and try to predict the next word in a sentence or something like that.\n",
      "\n",
      "What makes them large? I guess it's not just the size of the model, but also the complexity. Maybe they have a lot of parameters or layers, making them more powerful. They can handle more advanced tasks than simpler models.\n",
      "\n",
      "I've heard of specific models like GPT-3 and ChatGPT. Those are examples of large language models. They can do things like answer questions, write text, and even have conversations. But I'm not sure how they're different from smaller models. Maybe the size of the dataset they're trained on makes a big difference?\n",
      "\n",
      "Applications must be everywhere now. I know they're used in customer service, writing assistance, maybe even in education or creative fields. They can help generate content, translate languages, or provide explanations on various topics. That's pretty versatile.\n",
      "\n",
      "But I also remember hearing about some challenges with LLMs. Like, they can generate text that's not always accurate or makes up facts. So, they might produce incorrect information or be biased if they're trained on biased data. That's important to consider when using them.\n",
      "\n",
      "Are there different types of LLMs? I think there are variations based on their size or the kind of tasks they're good at. Some might be better at answering specific questions, others at writing or summarizing. It would be good to mention that in the introduction.\n",
      "\n",
      "I should also talk about how they've changed the way we use technology. With LLMs, we can interact with technology in more natural ways, like through conversations. They make accessing information and creating content easier, but they also have limitations that users should be aware of.\n",
      "\n",
      "Wait, should I include something about the development history? Maybe mention how they've evolved from early models to the advanced ones today, like GPT-3 and beyond. That could give context on their progression and impact.\n",
      "\n",
      "I think I have a rough idea. Now, I need to organize these thoughts into a coherent introduction. Start with a definition, then how they work, their characteristics, applications, challenges, and maybe a note on their impact and limitations. That should cover the main points without getting too technical.\n",
      "\n",
      "I should make sure the introduction is clear and concise, suitable for someone who might not be very familiar with the topic. Avoid jargon where possible, or explain it when necessary. Maybe start with a broad statement about their importance and then delve into specifics.\n",
      "\n",
      "Also, I should mention that while LLMs are powerful, they aren't perfect. They have limitations like the risk of generating misinformation or biased content, so it's important to use them with caution and understanding.\n",
      "\n",
      "I think that's a good structure. Now, I'll try to put it all together in a natural, flowing way.\n",
      "</think>\n",
      "\n",
      "Large Language Models (LLMs) are advanced AI systems designed to understand and generate human language at unprecedented levels. Trained on vast datasets comprising texts from various sources, they leverage deep learning techniques, typically neural networks, to process and recognize patterns in language. This enables them to perform a wide range of tasks, from answering questions and generating text to facilitating conversations. Their size and complexity, often involving millions of parameters, allow them to handle intricate linguistic tasks that simpler models struggle with.\n",
      "\n",
      "LLMs like GPT-3 and ChatGPT are notable examples, excelling in applications such as customer service, creative writing, and educational support. They can translate languages, provide explanations, and assist in various creative endeavors. However, their widespread use is not without challenges. They may produce inconsistent or incorrect information and can reflect biases present in their training data, necessitating careful use.\n",
      "\n",
      "While LLMs have revolutionized how we interact with technology through natural language interactions, they also have limitations, such as the potential for misinformation. Understanding these aspects is crucial for effectively utilizing these tools. As they continue to evolve, LLMs promise to enhance our access to information and creativity, though their development and application require awareness of their capabilities and constraints.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(generated_ids[0], skip_special_tokens=True).strip(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ce6d93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
